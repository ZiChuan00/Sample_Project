{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRV3tdInvpA9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OypFoxEyvpA_"
   },
   "outputs": [],
   "source": [
    "# 6.1 Identifying Missing Data\n",
    "# We will use the orders table from Super Store for these tasks\n",
    "orders = pd.read_csv('./datasets/orders.csv')\n",
    "\n",
    "\n",
    "# A. Start with some exploratory analysis methods to inspect the data\n",
    "orders.head()\n",
    "orders.info()\n",
    "orders.columns\n",
    "orders.shape\n",
    "pd.DataFrame(orders.dtypes, columns=[\"DataTypes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KBLD8NMvpBA"
   },
   "outputs": [],
   "source": [
    "# B. Which column has the most missing data? Sort the columns by sum of null values\n",
    "orders.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNZToEZOvpBA"
   },
   "outputs": [],
   "source": [
    "# C. Looks like postal_code is our biggest problem, along with region_id\n",
    "# Use a combination of filtering, isnull, and sum to count how many rows are missing both columns\n",
    "orders[orders['postal_code'].isnull()]['region_id'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hV0AmQgWvpBA"
   },
   "outputs": [],
   "source": [
    "# D. Let's drop the region_id nulls from the dataframe before proceeding\n",
    "orders.dropna(subset=['region_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecYgAvdqvpBA"
   },
   "outputs": [],
   "source": [
    "# E. It's the dream scenario! The IT team confirms all missing postal_code values should be 10001.0\n",
    "orders['postal_code'].fillna(10001.0, inplace=True)\n",
    "orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RI7tqHOvpBB"
   },
   "outputs": [],
   "source": [
    "# 6.2 Cleaning Our Data\n",
    "# A. Write a profit_margin function that accepts a row of data, which is a dictionary\n",
    "#    It should return the result of dividing the profit column by the sales column (i.e. profit/sales)\n",
    "def profit_margin(row):\n",
    "    return row['profit'] / row['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRGy5UssvpBB"
   },
   "outputs": [],
   "source": [
    "# B. Create a new column in the orders dataframe called 'profit_margin' by applying the profit margin function row-by-row\n",
    "orders['profit_margin'] = orders.apply(profit_margin, axis=1)\n",
    "\n",
    "# Note: an alternative way to do this without a function would be:\n",
    "orders['profit_margin'] = orders['profit'] / orders['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuSMEoTevpBB"
   },
   "outputs": [],
   "source": [
    "# C. Use the same process to create a new column called margin_category\n",
    "# If the profit_margin is less than 0, the margin_category should be \"unprofitable\"\n",
    "# If the profit_margin is 0, the margin_category should be \"break even\"\n",
    "# If the profit_margin is above 0, the margin_category should \"profitable\"\n",
    "def margin_categorization(row):\n",
    "    if row['profit_margin'] > 0:\n",
    "        return \"profitable\"\n",
    "    elif row['profit_margin'] == 0:\n",
    "        return \"break even\"\n",
    "    else:\n",
    "        return \"unprofitable\"\n",
    "orders['margin_category'] = orders.apply(margin_categorization, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xauu-t6_vpBC"
   },
   "outputs": [],
   "source": [
    "# D. How many of our orders were unprofitable?\n",
    "orders[orders['margin_category'] == \"unprofitable\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrT3TQx2vpBC"
   },
   "outputs": [],
   "source": [
    "# 6.3 GroupBy Insights\n",
    "# Segment the following data and explore aggregate values to answer the following questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPGmpZR5vpBC"
   },
   "outputs": [],
   "source": [
    "# A. Which discount results in the highest mean order quantity?\n",
    "orders.groupby('discount')['quantity'].mean().sort_values(ascending=False).iloc[[0]].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Kt5tysEvpBC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# B. Which product has the highest mean price discount applied?\n",
    "orders.groupby('product_id')['discount'].mean().sort_values(ascending=False).iloc[[0]].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYtbs_4HvpBC"
   },
   "outputs": [],
   "source": [
    "# 6.4 Joining DataFrames\n",
    "# The below example joins our first two dataframes by their shared column, Symbol\n",
    "openprice = pd.DataFrame({'Symbol': ['AAPL', 'DHR', 'DAL', 'AMZN'], 'OpenPrice': [217.51, 96.54, 51.45, 1703.34]})\n",
    "wkhigh = pd.DataFrame({'Symbol': ['DAL', 'AMZN', 'AAPL', 'DHR'], '52wkHigh': [60.79, 2050.49, 233.47, 110.11]})\n",
    "combined = pd.merge(openprice, wkhigh, how=\"left\", left_on='Symbol', right_on='Symbol')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLR_jE_DvpBC"
   },
   "outputs": [],
   "source": [
    "# A. Join the stockname dataframe to our combined result and print the result\n",
    "stockname = pd.DataFrame({'Symbol': ['AMZN', 'DHR', 'DAL', 'AAPL'], 'Name': ['Amazon', 'Danaher', 'Delta Airlines', 'Apple']})\n",
    "combined = pd.merge(combined, stockname, how=\"left\", on=\"Symbol\")\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcr3dLWCvpBD"
   },
   "outputs": [],
   "source": [
    "# B. Use the following tables from Super Store\n",
    "products = pd.read_csv('./datasets/products.csv')\n",
    "orders = pd.read_csv('./datasets/orders.csv')\n",
    "returns = pd.read_csv('./datasets/returns.csv')\n",
    "regions = pd.read_csv('./datasets/regions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LhPXUitvpBD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# i. We want to join the products and orders dataframes. \n",
    "#    Explore both dataframes to identify the common column between them\n",
    "#    Use a left join to combine the tables in a dataframe named orders_with_products\n",
    "orders_with_products = pd.merge(left=products, right=orders, how=\"left\", on=\"product_id\")\n",
    "orders_with_products.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOowb2qvvpBE"
   },
   "outputs": [],
   "source": [
    "# ii. Left join the orders_with_products and returns dataframes\n",
    "orders_with_products_and_returns = pd.merge(left=orders_with_products, right=returns, how=\"left\", on=\"order_id\")\n",
    "orders_with_products_and_returns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svYU6wAzvpBE"
   },
   "outputs": [],
   "source": [
    "# iii. Finally, add the region data to our combined dataframe\n",
    "orders_with_products_and_returns_and_regions = pd.merge(left=orders_with_products_and_returns, right=regions, how=\"left\", on=\"region_id\")\n",
    "orders_with_products_and_returns_and_regions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J99oElKmvpBF"
   },
   "outputs": [],
   "source": [
    "# iv. Let's use this combined dataframe to determine the salesperson generating the most profit\n",
    "orders_with_products_and_returns_and_regions.groupby('salesperson')['profit'].sum().sort_values(ascending=False).iloc[[0]].index[0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "6_09_Cleaning_and_Combining_Data_with_pandas_Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
